{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'more than 50'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 56\u001b[0m\n\u001b[0;32m     42\u001b[0m queries \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhich ships have a grid with more than 50 gb ram?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhich system is in the blockage on ship umbra?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSnr of SCPC_1 system in theta ship ?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m ]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[1;32m---> 56\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINPUT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUTPUT:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m, in \u001b[0;36mprocess_query\u001b[1;34m(input_query)\u001b[0m\n\u001b[0;32m     26\u001b[0m     output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mship_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: ent\u001b[38;5;241m.\u001b[39mtext})\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ent\u001b[38;5;241m.\u001b[39mlabel_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCARDINAL\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 28\u001b[0m     output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid_ram\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m})\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ent\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblockage\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     30\u001b[0m     output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_in_blockage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'more than 50'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def process_query(input_query):\n",
    "    doc = nlp(input_query)\n",
    "    output = {'select_column': None, 'from_table': None, 'where': []}\n",
    "\n",
    "    # Identify entities and conditions in the query\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'nsubj':\n",
    "            output['select_column'] = token.text\n",
    "        elif token.dep_ == 'ROOT':\n",
    "            output['from_table'] = token.text\n",
    "        elif token.dep_ == 'attr' and token.head.dep_ == 'prep':\n",
    "            output['select_column'] = token.head.text\n",
    "        elif token.dep_ == 'pobj' and token.head.dep_ == 'prep':\n",
    "            output['from_table'] = token.text\n",
    "        elif token.dep_ == 'nsubjpass' and token.head.dep_ == 'prep':\n",
    "            output['from_table'] = token.text\n",
    "\n",
    "    # Extract conditions\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'GPE' or ent.label_ == 'PERSON':\n",
    "            output['where'].append({'column': 'ship_name', 'relation': '=', 'value': ent.text})\n",
    "        elif ent.label_ == 'CARDINAL':\n",
    "            output['where'].append({'column': 'grid_ram', 'relation': '>', 'value': int(ent.text)})\n",
    "        elif ent.text == 'blockage':\n",
    "            output['where'].append({'column': 'is_in_blockage', 'relation': '=', 'value': 1})\n",
    "        elif ent.text == 'signal':\n",
    "            output['where'].append({'column': 'system_signal', 'relation': '=', 'value': 1})\n",
    "        elif ent.text == 'SNR':\n",
    "            output['where'].append({'column': 'system_snr', 'relation': '=', 'value': int(doc[doc.index(ent) + 1].text)})\n",
    "        elif ent.text == 'uptime':\n",
    "            output['where'].append({'column': 'grid_uptime', 'relation': '>', 'value': int(doc[doc.index(ent) + 1].text) * 60})\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# Test cases\n",
    "queries = [\n",
    "    \"Which ships have a grid with more than 50 gb ram?\",\n",
    "    \"Which system is in the blockage on ship umbra?\",\n",
    "    \"Which grid in nebula has more than 60gb ram?\",\n",
    "    \"Name of the ship which is in blockage and has the first letter as ‘g’?\",\n",
    "    \"What are the grid versions currently active on the ship eta?\",\n",
    "    \"What are the signal strength on the ship ‘mu’?\",\n",
    "    \"When was grid hub1_LD5 updated on the ship gamma?\",\n",
    "    \"Which ships have a sound to noise ratio of 50?\",\n",
    "    \"Which ships have a grid consuming less than 20 gb memory but has an uptime of more than 6 hours?\",\n",
    "    \"Snr of SCPC_1 system in theta ship ?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    output = process_query(query)\n",
    "    print(f\"INPUT: {query}\")\n",
    "    print(\"OUTPUT:\", output)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Which', 'JJ'), ('system', 'NN'), ('is', 'VBZ'), ('in', 'IN'), ('the', 'DT'), ('blockage', 'NN'), ('on', 'IN'), ('ship', 'NN'), ('umbra', 'NN'), ('?', '.')] JJ\n",
      "[('Name', 'NN'), ('of', 'IN'), ('the', 'DT'), ('ship', 'NN'), ('which', 'WDT'), ('is', 'VBZ'), ('in', 'IN'), ('blockage', 'NN'), ('and', 'CC'), ('has', 'VBZ'), ('the', 'DT'), ('first', 'JJ'), ('letter', 'NN'), ('as', 'IN'), ('‘', 'NN'), ('g', 'NN'), ('’', 'NN'), ('?', '.')]\n",
      "[('Which', 'JJ'), ('ships', 'NNS'), ('have', 'VBP'), ('a', 'DT'), ('grid', 'NN'), ('with', 'IN'), ('more', 'JJR'), ('than', 'IN'), ('50', 'CD'), ('gb', 'NN'), ('ram', 'NN'), ('?', '.')]\n",
      "[('Which', 'WDT'), ('grid', 'NN'), ('in', 'IN'), ('nebula', 'NN'), ('has', 'VBZ'), ('more', 'JJR'), ('than', 'IN'), ('60gb', 'CD'), ('ram', 'NN'), ('?', '.')]\n",
      "[('What', 'WP'), ('are', 'VBP'), ('the', 'DT'), ('signal', 'JJ'), ('strength', 'NN'), ('on', 'IN'), ('the', 'DT'), ('ship', 'NN'), ('‘', 'NNP'), ('mu', 'NN'), ('’', 'NN'), ('?', '.')]\n",
      "[('When', 'WRB'), ('was', 'VBD'), ('grid', 'JJ'), ('hub1_LD5', 'NN'), ('updated', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('ship', 'NN'), ('gamma', 'NN'), ('?', '.')]\n",
      "[('Which', 'JJ'), ('ships', 'NNS'), ('have', 'VBP'), ('a', 'DT'), ('sound', 'NN'), ('to', 'TO'), ('noise', 'VB'), ('ratio', 'NN'), ('of', 'IN'), ('50', 'CD'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def pos_tagging(query):\n",
    "    tokens = word_tokenize(query)\n",
    "    tagged = pos_tag(tokens)\n",
    "    noun = []\n",
    "    for i in range(len(tagged)):\n",
    "        if tagged[i][1] == 'NN':\n",
    "            noun.append(tagged[i][0])\n",
    "    return tagged\n",
    "\n",
    "# Example\n",
    "query = \"Which system is in the blockage on ship umbra?\"\n",
    "query2 = \"Name of the ship which is in blockage and has the first letter as ‘g’?\"\n",
    "query3 = \"Which ships have a grid with more than 50 gb ram?\"\n",
    "query4 = \"Which grid in nebula has more than 60gb ram?\"\n",
    "query5 = \"Name of the ship which is in blockage and has the first letter as ‘g’?\"\n",
    "\n",
    "query6 = \"What are the signal strength on the ship ‘mu’?\"\n",
    "query7 = \"When was grid hub1_LD5 updated on the ship gamma?\"\n",
    "query8 = \"Which ships have a sound to noise ratio of 50?\"\n",
    "\n",
    "pos_tags = pos_tagging(query)\n",
    "pos_tags2 = pos_tagging(query2)\n",
    "pos_tags3 = pos_tagging(query3)\n",
    "pos_tags4 = pos_tagging(query4)\n",
    "pos_tags5 = pos_tagging(query5)\n",
    "pos_tags5 = pos_tagging(query6)\n",
    "pos_tags6 = pos_tagging(query7)\n",
    "pos_tags7 = pos_tagging(query8)\n",
    "print(pos_tags,pos_tags[0][1])\n",
    "print(pos_tags2)\n",
    "print(pos_tags3)\n",
    "print(pos_tags4)\n",
    "print(pos_tags5)\n",
    "print(pos_tags6)\n",
    "print(pos_tags7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Which ships have a grid with more than 50 gb ram?\n",
      "Output: -> {'select_column': 'ram', 'from_table': 'grid_details', 'where': []}\n",
      "\n",
      "Input: Which system is in the blockage on ship umbra?\n",
      "Output: -> {'select_column': 'umbra', 'from_table': 'rf_stats', 'where': []}\n",
      "\n",
      "Input: Which grid in nebula has more than 60gb ram?\n",
      "Output: -> {'select_column': 'ram', 'from_table': 'grid_details', 'where': []}\n",
      "\n",
      "Input: Name of the ship which is in blockage and has the first letter as ‘g’?\n",
      "Output: -> {'select_column': 'g', 'from_table': 'rf_stats', 'where': []}\n",
      "\n",
      "Input: What are the grid versions currently active on the ship eta?\n",
      "Output: -> {'select_column': 'eta', 'from_table': 'rf_stats', 'where': []}\n",
      "\n",
      "Input: What are the signal strength on the ship ‘mu’?\n",
      "Output: -> {'select_column': 'mu', 'from_table': 'rf_stats', 'where': []}\n",
      "\n",
      "Input: When was grid hub1_LD5 updated on the ship gamma?\n",
      "Output: -> {'select_column': 'gamma', 'from_table': 'rf_stats', 'where': []}\n",
      "\n",
      "Input: Which ships have a sound to noise ratio of 50?\n",
      "Output: -> {'select_column': '50', 'from_table': None, 'where': []}\n",
      "\n",
      "Input: Which ships have a grid consuming less than 20 gb memory but has an uptime of more than 6 hours?\n",
      "Output: -> {'select_column': 'hours', 'from_table': 'grid_details', 'where': []}\n",
      "\n",
      "Input: Snr of SCPC_1 system in theta ship ?\n",
      "Output: -> {'select_column': 'theta', 'from_table': 'rf_stats', 'where': []}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def parse_query(query):\n",
    "    tokens = word_tokenize(query.lower())  # Tokenize and convert to lowercase\n",
    "    stop_words = set(stopwords.words('english'))  # Remove stopwords\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    # Define relations and operators\n",
    "    relations = ['=', '>', '<', 'like']\n",
    "    operators = ['and', 'or']\n",
    "\n",
    "    # Initialize variables\n",
    "    select_column = None\n",
    "    from_table = None\n",
    "    where_conditions = []\n",
    "\n",
    "    # Parse the query\n",
    "    for i, token in enumerate(filtered_tokens):\n",
    "        if token == 'ship':\n",
    "            from_table = 'rf_stats'\n",
    "        elif token == 'grid':\n",
    "            from_table = 'grid_details'\n",
    "        elif token in relations:\n",
    "            if filtered_tokens[i - 1] == 'ship' or filtered_tokens[i - 1] == 'grid':\n",
    "                condition = {'column': filtered_tokens[i - 1] + '_name',\n",
    "                             'relation': token}\n",
    "                if token == 'like':\n",
    "                    condition['value'] = filtered_tokens[i + 1] + '%'\n",
    "                else:\n",
    "                    condition['value'] = filtered_tokens[i + 1]\n",
    "                where_conditions.append(condition)\n",
    "        elif token in operators:\n",
    "            continue\n",
    "        else:\n",
    "            select_column = token\n",
    "\n",
    "    return {'select_column': select_column, 'from_table': from_table, 'where': where_conditions}\n",
    "\n",
    "queries = [\n",
    "    \"Which ships have a grid with more than 50 gb ram?\",\n",
    "    \"Which system is in the blockage on ship umbra?\",\n",
    "    \"Which grid in nebula has more than 60gb ram?\",\n",
    "    \"Name of the ship which is in blockage and has the first letter as ‘g’?\",\n",
    "    \"What are the grid versions currently active on the ship eta?\",\n",
    "    \"What are the signal strength on the ship ‘mu’?\",\n",
    "    \"When was grid hub1_LD5 updated on the ship gamma?\",\n",
    "    \"Which ships have a sound to noise ratio of 50?\",\n",
    "    \"Which ships have a grid consuming less than 20 gb memory but has an uptime of more than 6 hours?\",\n",
    "    \"Snr of SCPC_1 system in theta ship ?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    result = parse_query(query)\n",
    "    print(f\"Input: {query}\")\n",
    "    print(\"Output: ->\", result)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Which', 'ships', 'have', 'a', 'grid', 'with', 'more', 'than', '50', 'gb', 'ram', '?']\n",
      "['ships', 'grid', '50', 'gb', 'ram']\n",
      "{'select_column': '', 'from_table': '', 'where': []}\n",
      "['Which', 'system', 'is', 'in', 'the', 'blockage', 'on', 'ship', 'umbra', '?']\n",
      "['system', 'blockage', 'ship', 'umbra']\n",
      "{'select_column': '', 'from_table': '', 'where': []}\n",
      "['Which', 'grid', 'in', 'nebula', 'has', 'more', 'than', '60gb', 'ram', '?']\n",
      "['grid', 'nebula', '60gb', 'ram']\n",
      "{'select_column': '', 'from_table': '', 'where': []}\n",
      "['Name', 'of', 'the', 'ship', 'which', 'is', 'in', 'blockage', 'and', 'has', 'the', 'first', 'letter', 'as', '‘', 'g', '’', '?']\n",
      "['name', 'ship', 'blockage', 'first', 'letter', 'g']\n",
      "{'select_column': 'system', 'from_table': 'rf_stats', 'where': [{'column': 'ship_name', 'relation': '=', 'value': 'blockage'}]}\n",
      "['What', 'are', 'the', 'grid', 'versions', 'currently', 'active', 'on', 'the', 'ship', 'eta', '?']\n",
      "['grid', 'versions', 'currently', 'active', 'ship', 'eta']\n",
      "{'select_column': '', 'from_table': '', 'where': []}\n",
      "['What', 'are', 'the', 'signal', 'strength', 'on', 'the', 'ship', '‘', 'mu', '’', '?']\n",
      "['signal', 'strength', 'ship', 'mu']\n",
      "{'select_column': '', 'from_table': '', 'where': []}\n",
      "['When', 'was', 'grid', 'hub1_LD5', 'updated', 'on', 'the', 'ship', 'gamma', '?']\n",
      "['grid', 'updated', 'ship', 'gamma']\n",
      "{'select_column': '', 'from_table': '', 'where': []}\n",
      "['Which', 'ships', 'have', 'a', 'sound', 'to', 'noise', 'ratio', 'of', '50', '?']\n",
      "['ships', 'sound', 'noise', 'ratio', '50']\n",
      "{'select_column': '', 'from_table': '', 'where': []}\n",
      "['Which', 'ships', 'have', 'a', 'grid', 'consuming', 'less', 'than', '20', 'gb', 'memory', 'but', 'has', 'an', 'uptime', 'of', 'more', 'than', '6', 'hours', '?']\n",
      "['ships', 'grid', 'consuming', 'less', '20', 'gb', 'memory', 'uptime', '6', 'hours']\n",
      "{'select_column': '', 'from_table': '', 'where': []}\n",
      "['Snr', 'of', 'SCPC_1', 'system', 'in', 'theta', 'ship', '?']\n",
      "['snr', 'system', 'theta', 'ship']\n",
      "{'select_column': '', 'from_table': '', 'where': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define the datasets and column details\n",
    "datasets = {\n",
    "    'rf_stats': {\n",
    "        'columns': ['ship_name', 'system', 'system_signal', 'is_in_blockage', 'system_snr']\n",
    "    },\n",
    "    'grid_details': {\n",
    "        'columns': ['ship_name', 'grid_name', 'grid_version', 'grid_uptime', 'grid_time_since_version_change', 'grid_ram', 'grid_last_version']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the NLTK stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def generate_query(input_text):\n",
    "    tokens = word_tokenize(input_text)\n",
    "    filtered_tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words]\n",
    "    print(filtered_tokens)\n",
    "    select_column = ''\n",
    "    from_table = ''\n",
    "    where = []\n",
    "    \n",
    "    if 'ship' in filtered_tokens and 'name' in filtered_tokens:\n",
    "        if 'grid' in filtered_tokens:\n",
    "            select_column = 'ship_name'\n",
    "            from_table = 'grid_details'\n",
    "        else:\n",
    "            select_column = 'system'\n",
    "            from_table = 'rf_stats'\n",
    "            \n",
    "        ship_index = filtered_tokens.index('ship')\n",
    "        ship_name = filtered_tokens[ship_index + 1]\n",
    "        where.append({'column': 'ship_name', 'relation': '=', 'value': ship_name})\n",
    "        \n",
    "        if 'grid' in filtered_tokens:\n",
    "            ram_index = filtered_tokens.index('ram')\n",
    "            condition_value = filtered_tokens[ram_index - 1]\n",
    "            where.append({'column': 'grid_ram', 'relation': '>', 'value': condition_value})\n",
    "        \n",
    "    # Add more conditions based on the input_text\n",
    "    \n",
    "    query = {\n",
    "        'select_column': select_column,\n",
    "        'from_table': from_table,\n",
    "        'where': where\n",
    "    }\n",
    "    \n",
    "    return query\n",
    "\n",
    "# Test the function with the provided test cases\n",
    "test_cases = [\n",
    "    \"Which ships have a grid with more than 50 gb ram?\",\n",
    "    \"Which system is in the blockage on ship umbra?\",\n",
    "    \"Which grid in nebula has more than 60gb ram?\",\n",
    "    \"Name of the ship which is in blockage and has the first letter as ‘g’?\",\n",
    "    \"What are the grid versions currently active on the ship eta?\",\n",
    "    \"What are the signal strength on the ship ‘mu’?\",\n",
    "    \"When was grid hub1_LD5 updated on the ship gamma?\",\n",
    "    \"Which ships have a sound to noise ratio of 50?\",\n",
    "    \"Which ships have a grid consuming less than 20 gb memory but has an uptime of more than 6 hours?\",\n",
    "    \"Snr of SCPC_1 system in theta ship?\"\n",
    "]\n",
    "\n",
    "for test_case in test_cases:\n",
    "    print(generate_query(test_case))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
